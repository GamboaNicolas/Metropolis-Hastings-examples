---
title: "Metropolis-Hasting"
format: 
  pdf:
    fig-pos: "H"
lang: es
echo: FALSE
message: FALSE
warning: FALSE
geometry:
  - top= 25mm
  - left= 20mm
  - right = 20mm
  - bottom = 25mm
  - heightrounded
header-includes:
  - \usepackage{ragged2e}
  - \usepackage{hyperref}

---


```{r Carga de librerias}
library(tidyverse)
library(mvtnorm)
library(patchwork)
library(tinytable)
```

```{r Configuraciones predeterminadas}
knitr::opts_chunk$set(fig.align = "center", out.width = "70%")

set.seed("2126519")

theme_set(theme_bw())
```


# Metropolis-Hasting en una dimensión
  
A continuación se presenta...


:::callout-note
## Algoritmo M-H univariado

```{r Algoritmo M-H univariado}
sample_mh <- function(n, 
                      d_objetivo, 
                      r_propuesta = NULL,
                      d_propuesta = NULL,
                      p_inicial = NULL){

  if (is.null(r_propuesta) | is.null(d_propuesta)) {
    r_propuesta <- function(media) rnorm(n = 1, media, sd = 1)
    d_propuesta <- function(x, media) dnorm(x = x,media, sd = 1)
  }
  
  stopifnot(n > 0)
  contador <- 0
  muestras <- numeric(n)
  
  if (is.null(p_inicial)) {
    for(i in 1:1000){
      p_inicial <- runif(1,-100,100)
      if (d_objetivo(p_inicial) != 0) {
        break
      }
    }
    if(i == 1000) stop("Se recomienda introducir un valor para ´p_inicial´")
  }
  
  muestras[1] <- p_inicial

  for(i in 2:n) {
    
    p_actual <- muestras[i-1]
    p_propuesta <- r_propuesta(p_actual)

    q_actual <- d_propuesta(p_actual, p_propuesta)
    q_nuevo <- d_propuesta(p_propuesta, p_actual)
    
    f_actual <- d_objetivo(p_actual)
    f_nuevo <- d_objetivo(p_propuesta)

    alfa <- min(1, (f_nuevo/f_actual)*(q_actual/q_nuevo))

    muestras[i] <- sample(c(p_propuesta, p_actual),
    size = 1, prob = c(alfa, 1-alfa))
    
    if(muestras[i] != muestras[i-1]) {
      contador <- contador + 1
    }
  }
  return(list(cadena = data.frame(iteracion = 1:n, x = muestras), 
       tasa_aceptacion = contador / n))
}


# d_obj <- function(x){
#   # dnorm(x = x,mean = 90,sd = 8)
#   return(dbeta(x = x,2,2))
# }
# d_obj(-50)
# muestra <- sample_mh(100000, d_objetivo = d_obj)
# 
# muestra |> 
#   ggplot()+
#   aes(x = x)+
#   geom_histogram()
```
:::


# Distribución de Kumaraswamy




```{r distribucion de kumaraswamy}
grilla <- seq(0, 1, length.out = 502)[c(-1,-502)]
d_kuma <- function(x, a = 6, b = 2){
  
  if(a<0 | b<0) stop("Poneme a y b positivos no te cuesta nada")
  
  salida <- a*b*x^(a-1)*(1-x^a)^(b-1)
  
  salida[which(x <= 0 | x >= 1)] <- 0
  
  salida
}



tibble(
  x = rep(grilla,times = 5),
  parametros = rep(c("a = 0.5, b = 0.5",
                     "a = 1, b = 2",
                     "a = 3, b = 4",
                     "a = 6, b = 2",
                     "a = 5, b = 1"), each = 500),
  valores = c(
    d_kuma(grilla, 0.5, 0.5),
    d_kuma(grilla, 1, 2),
    d_kuma(grilla, 3, 4),
    d_kuma(grilla, 6, 2),
    d_kuma(grilla, 5,1)
  )
) |> 
  ggplot()+
  aes(x = x, y = valores,color = parametros)+
  geom_line(linewidth = 1.2)

# tibble(
#   x = rep(grilla,times = 5),
#   parametros = rep(c("a = 0.5, b = 0.5",
#                      "a = 1, b = 2",
#                      "a = 3, b = 4",
#                      "a = 6, b = 2",
#                      "a = 5, b = 1"), each = 500),
#   valores = c(
#     dbeta(grilla, 0.5, 0.5),
#     dbeta(grilla, 1, 2),
#     dbeta(grilla, 3, 4),
#     dbeta(grilla, 6, 2),
#     dbeta(grilla, 5,1)
#   )
# ) |> 
#   ggplot()+
#   aes(x = x, y = valores,color = parametros)+
#   geom_line(linewidth = 1.2)
# 

```


Esta distribución puede ser utilizada en el ámbito de la estadística bayesiana a la hora de definir un prior para un parámetro con campo de variación en el intervalo (0, 1).

Por lo general la distribución elegida para estas situaciones suele ser la beta ya que presenta ventajas como ser una distribución conjugada de la binomial, lo cual puede facilitar mucho algunos cálculos. El problema es que para calcular la densidad de esta es que depende de la función gamma, la cual es una integral, y en algunas situaciones se puede complicar su cálculo.

La distribución de Kumaraswamy se comporta de manera muy similar a la beta, sin tener el problema de la dificultad del cálculo de la densidad. 


```{r comparacion de las cadenas}
source("Funciones.R")

get_beta_param <- function(media, kappa) {
  alpha <- media*kappa
  beta <- (1-media)*kappa
  
  return(list(alpha = alpha, beta = beta))
}
```


```{r cadenas markov, include=F}
valores_kappa <- c(1, 2, 5)

graficos <- list(Kappa1 = NULL, Kappa2 = NULL, Kappa5 = NULL)

df_cadenas <- list(data_cadena_1 = NULL, data_cadena_2 = NULL, data_cadena_3 = NULL)

for(i in 1:3) {
  r_prop <- function(x) {
  kappa <- valores_kappa[i]
  pars <- get_beta_param(x, kappa)
  rbeta(1, shape1 = pars$alpha, shape2 = pars$beta)
}
d_prop <- function(x, mean) {
  kappa <- valores_kappa[i]
  pars <- get_beta_param(mean, kappa)
  dbeta(x, shape1 = pars$alpha, shape2 = pars$beta)
}

muestra <- sample_mh(n = 5000, d_objetivo = d_kuma, r_propuesta = r_prop, d_propuesta = d_prop, p_inicial = rbeta(1,2,2))

ap1 <- plot_autocor(muestra = muestra$cadena)

tp1 <- plot_trace(muestra = muestra$cadena)

hp1 <- plot_hist(muestra = muestra$cadena, d_objetivo = d_kuma)

graficos[[i]] <- (tp1 / (hp1 + ap1))

df_cadenas[[i]] <- muestra
}
```


```{r cadena 1}
#| fig-cap: "Muestreo por Metropolis-Hastings con concentación de 1"

graficos$Kappa1
```


```{r cadena 2}
#| fig-cap: "Muestreo por Metropolis-Hastings con concentación de 2"

graficos$Kappa2
```


```{r cadena 3}
#| fig-cap: "Muestreo por Metropolis-Hastings con concentación de 5"

graficos$Kappa5
```

```{r funcion x}
# Cadena 1
media_cadena_1 <- mean(df_cadenas$data_cadena_1$cadena$x) |> round(3)
percentiles_1 <- quantile(df_cadenas$data_cadena_1$cadena$x, c(0.05,0.95)) |> round(3)

# Cadena 2
media_cadena_2 <- mean(df_cadenas$data_cadena_2$cadena$x) |> round(3)
percentiles_2 <- quantile(df_cadenas$data_cadena_2$cadena$x, c(0.05,0.95)) |> round(3)

# Cadena 3
media_cadena_3 <- mean(df_cadenas$data_cadena_3$cadena$x) |> round(3)
percentiles_3 <- quantile(df_cadenas$data_cadena_3$cadena$x, c(0.05,0.95)) |> round(3)

```

```{r funcion logit}
logit <- function(x) log(x/(1-x))

# Cadena 1
media_cadena_lg_1 <- mean(logit(df_cadenas$data_cadena_1$cadena$x)) |> round(3)
percentiles_lg_1 <- quantile(logit(df_cadenas$data_cadena_1$cadena$x), c(0.05,0.95)) |> round(3)

# Cadena 2
media_cadena_lg_2 <- mean(logit(df_cadenas$data_cadena_2$cadena$x)) |> round(3)
percentiles_lg_2 <- quantile(logit(df_cadenas$data_cadena_2$cadena$x), c(0.05,0.95)) |> round(3)

# Cadena 3
media_cadena_lg_3 <- mean(logit(df_cadenas$data_cadena_3$cadena$x)) |> round(3)
percentiles_lg_3 <- quantile(logit(df_cadenas$data_cadena_3$cadena$x), c(0.05,0.95)) |> round(3)

```


```{r tablita fachera}
filas <- rep(c("$X$", "$Logit(X)$"), each = 3)
columnas <- c("Kappa", "Esperanza_estimada", "Quantil_0.05", "Quantil_0.95")

valores <- tibble(
  var = filas,
  kappa = rep(c(1,2,5), times = 2), 
  esp_est = c(media_cadena_1, media_cadena_2, media_cadena_3, media_cadena_lg_1, media_cadena_lg_2, media_cadena_lg_3),
  quantil_0.05 = c(percentiles_1[1], percentiles_2[1], percentiles_3[1], percentiles_lg_1[1], percentiles_lg_2[1], percentiles_lg_3[1]),
  quantil_0.95 = c(percentiles_1[2], percentiles_2[2], percentiles_3[2], percentiles_lg_1[2], percentiles_lg_2[2], percentiles_lg_3[2])
)

colnames(valores) <- c("$f(x)$" ,"$\\kappa$", "$\\hat{E(x)}$", "$\\hat{q_{0.05}}$", "$\\hat{q_{0.95}}$")

tablita <- valores |> 
  tt() |> 
  style_tt(i = c(1,4), j = 1, rowspan = 3, alignv = "t")
  # style_tt(i = c(1,4), j = c(2:5),background = "pink")
tablita
```






:::callout-note

```{r}
sample_mh <- function(n, d_objetivo, r_propuesta, d_propuesta, p_inicial = NULL) {

  stopifnot(n > 0)
  muestras <- matrix(0,nrow = n,ncol = length(p_inicial))
  muestras[1, ] <- p_inicial
  
  for(i in 2:n) {
    p_actual <- muestras[i-1,]
    p_propuesta <- r_propuesta(p_actual)
    
    q_actual <- d_propuesta(p_actual, p_propuesta)
    q_nuevo <- d_propuesta(p_propuesta, p_actual)
    
    f_actual <- d_objetivo(p_actual)
    f_nuevo <- d_objetivo(p_propuesta)
    
    alfa <- min(1, (f_nuevo/f_actual)*(q_actual/q_nuevo))
    
    aceptar <- rbinom(1,1,alfa)
    
    if (aceptar) {
      muestras[i,] <- p_propuesta
    }else{
      muestras[i,] <- p_actual
    }
  }
  salida <- data.frame(iteracion = 1:n, x = muestras)
  colnames(salida) <- c("iteracion", paste0("dim_",1:length(p_inicial)))
  return(salida)
}


```
:::

